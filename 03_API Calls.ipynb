{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a9b9b6b",
   "metadata": {},
   "source": [
    "# API Calls\n",
    "\n",
    "To Improve our model, we'll add additional data regarding the natural environment given the coordinates provided for each fire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33be922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pickle\n",
    "import time\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from pytz import timezone \n",
    "from datetime import datetime, timedelta, timezone\n",
    "from meteostat import Stations, Daily, Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e0b6d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/df_description.pkl', 'rb') as f:\n",
    "    df_description = pickle.load(f)\n",
    "    \n",
    "with open('pickles/df_model.pkl', 'rb') as f:\n",
    "    df_model = pickle.load(f)\n",
    "    \n",
    "with open('pickles/df_soil.pkl', 'rb') as f:\n",
    "    df_soil = pickle.load(f)\n",
    "    \n",
    "with open('pickles/df_elev.pkl', 'rb') as f:\n",
    "    df_elev = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ef8b4",
   "metadata": {},
   "source": [
    "### OpenMeteo API Elevation Data\n",
    "\n",
    "To improve our model results, we'll be using the OpenMeteo Library, which takes in coordinates and the date the fire was discovered and returns elevation data. This elevation data is expected to provide clarity regarding the causes of fires, as specific causes are less likely to occur at higher elevations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f020b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'elevation': [109.0]}\n",
      "{'elevation': [147.0]}\n",
      "{'elevation': [117.0]}\n",
      "{'elevation': [109.0]}\n",
      "{'elevation': [109.0]}\n",
      "{'elevation': [117.0]}\n",
      "{'elevation': [117.0]}\n",
      "{'elevation': [100.0]}\n",
      "{'elevation': [218.0]}\n",
      "{'elevation': [109.0]}\n",
      "{'elevation': [109.0]}\n",
      "{'elevation': [117.0]}\n",
      "{'elevation': [430.0]}\n",
      "{'elevation': [109.0]}\n",
      "{'elevation': [117.0]}\n",
      "{'elevation': [74.0]}\n",
      "{'elevation': [430.0]}\n",
      "{'elevation': [147.0]}\n",
      "{'elevation': [147.0]}\n",
      "{'elevation': [147.0]}\n",
      "{'elevation': [147.0]}\n",
      "{'elevation': [430.0]}\n",
      "{'elevation': [109.0]}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.open-meteo.com/v1/elevation\"\n",
    "batch_size = 100\n",
    "df_elevation = pd.DataFrame(columns=[\"LATITUDE\", \"LONGITUDE\", \"elevation\"])\n",
    "\n",
    "for i in range(0, len(df_description), batch_size):\n",
    "    df_batch = df_description.iloc[i:i+batch_size]\n",
    "    \n",
    "    for index, row in df_batch.iterrows():\n",
    "        lat, lon = row[\"LATITUDE\"], row[\"LONGITUDE\"]\n",
    "        params = {\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "        }\n",
    "        response = requests.get(url, params=params)\n",
    "        print(response.json())\n",
    "        elevation = response.json()[\"elevation\"][0]\n",
    "        df_temp = pd.DataFrame({\n",
    "            \"LATITUDE\": [lat],\n",
    "            \"LONGITUDE\": [lon],\n",
    "            \"elevation\": [elevation]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190e9078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elev = pd.concat([df_elevation, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37bbdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/df_elev.pkl', 'wb') as f:\n",
    "    pickle.dump(df_elev, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee427687",
   "metadata": {},
   "source": [
    "### SoilGrid API\n",
    "\n",
    "We'll call this API to gather information about the soil conditions at each coordinate. This API call will return a classification of the soil as clay, sand, or silt for a depth of 5-15cm, as well as additional data pertaining to the density and nutrient load of the soil.\n",
    "\n",
    "Soil conditions are a valuable component in our model as different soil types retain moisture more effectively than others and may support different types of vegetation. These variances in soil types may provide insight into the fuel density load that could sustain a fire at the given coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eae84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://rest.isric.org/soilgrids/v2.0/properties/query'\n",
    "soil_data = []\n",
    "\n",
    "properties = ['clay', 'sand', 'silt', 'cec', 'cfvo', 'nitrogen', 'soc', 'bdod','phh2o']\n",
    "depths = ['5-15cm']\n",
    "values = ['mean']\n",
    "\n",
    "# Set batch size\n",
    "batch_size = 6000\n",
    "\n",
    "# Iterate over batches of coordinates\n",
    "for i in range(0, len(df_description), batch_size):\n",
    "    # Get batch of coordinates\n",
    "    df_batch = df_description.iloc[i:i+batch_size]\n",
    "    \n",
    "    # Iterate over coordinates in batch\n",
    "    for index, row in df_batch.iterrows():\n",
    "        lat = row['LATITUDE']\n",
    "        lon = row['LONGITUDE']\n",
    "\n",
    "        # Make API request\n",
    "        params = {\n",
    "            'lon': lon,\n",
    "            'lat': lat,\n",
    "            'property': properties,\n",
    "            'depth': depths,\n",
    "            'value': values\n",
    "        }\n",
    "\n",
    "        headers = {'accept': 'application/json'}\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "        print(response)\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract soil data and add to list of dictionaries\n",
    "        soil_dict = {'LATITUDE': lat, 'LONGITUDE': lon}\n",
    "        for layer in data['properties']['layers']:\n",
    "            name = layer['name']\n",
    "            if name in ['clay','sand', 'silt','cec','cfvo','nitrogen','soc','bdod','phh2o']:\n",
    "                for depth in layer['depths']:\n",
    "                    value = depth['values']['mean']\n",
    "                    soil_dict[name] = value\n",
    "        soil_data.append(soil_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b5fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soil = pd.DataFrame.from_records(soil_data)\n",
    "df_soil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adedf8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/df_soil.pkl', 'wb') as f:\n",
    "    pickle.dump(df_soil, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6658f2",
   "metadata": {},
   "source": [
    "### Merging Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "464676cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elev = df_elev.dropna()\n",
    "df_elev['elevation'] = df_elev['elevation'].astype(str).apply(lambda x: [int(float(i)) for i in x.strip('[]').split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be13946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elev['elevation'] = [i[0] if isinstance(i, list) else i for i in df_elev['elevation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f2be0e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LATITUDE     float64\n",
       "LONGITUDE    float64\n",
       "elevation      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_elev.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73af0e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soil = df_soil.drop_duplicates()\n",
    "df_elev = df_elev.drop_duplicates()\n",
    "df_model = df_model.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86080acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_elev, df_soil, on = ['LATITUDE', 'LONGITUDE'], how='inner')\n",
    "df_merged.dropna(axis = 0)\n",
    "df = pd.merge(df_model,df_merged, on = ['LATITUDE', 'LONGITUDE'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47253c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76472, 21)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1c48dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DISCOVERY_DOY                   int64\n",
       "STAT_CAUSE_DESCR               object\n",
       "STATE                          object\n",
       "SOURCE_SYSTEM_TYPE             object\n",
       "duration                      float64\n",
       "FIRE_SIZE_CLASS                object\n",
       "LATITUDE                      float64\n",
       "LONGITUDE                     float64\n",
       "SOURCE_REPORTING_UNIT_NAME     object\n",
       "FIRE_YEAR                       int64\n",
       "FIRE_SIZE                     float64\n",
       "elevation                       int64\n",
       "bdod                          float64\n",
       "cec                           float64\n",
       "cfvo                          float64\n",
       "clay                          float64\n",
       "nitrogen                      float64\n",
       "phh2o                         float64\n",
       "sand                          float64\n",
       "silt                          float64\n",
       "soc                           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f0a58c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df.duplicated(subset =['LATITUDE', 'LONGITUDE','bdod','sand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b58efa52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11598"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89997c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "144b96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30571107",
   "metadata": {},
   "source": [
    "### Combining Target Variable Bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a09b33",
   "metadata": {},
   "source": [
    "Now that we have our complete dataset, we'll further condense our target feature by removing the Miscellaneous feature. Miscellaneous as a cause description doesn't provide enough information about the cause of the fire to accuractely model the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b71abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df[\"STAT_CAUSE_DESCR\"]!='Miscellaneous']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7914313",
   "metadata": {},
   "source": [
    "we'll then sort the children subclass of the STAT_CAUSE_DESCRIPTION feature to a new subclass called 'negligence' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "38d59655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['STAT_CAUSE_DESCR'] = np.where(df['STAT_CAUSE_DESCR'] == 'Children', 'Negligence',df['STAT_CAUSE_DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44374358",
   "metadata": {},
   "source": [
    "Finally, we'll sort the equipment use subclass into the a new infrastructure subclass. This infrastructure subclass is used to describe all instances of the built environment causing a fire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1af52818",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['STAT_CAUSE_DESCR'] = np.where(df['STAT_CAUSE_DESCR'] == 'Equipment Use','Infrastructure', df['STAT_CAUSE_DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90c1565",
   "metadata": {},
   "source": [
    "### Saving dfs as variables using Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6023336",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/df.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
